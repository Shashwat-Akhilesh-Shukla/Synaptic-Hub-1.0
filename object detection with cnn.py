# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OE7hbAL5nZgnJo751aJkwxzLxzw2DX6H
"""

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.applications import VGG16
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import SparseCategoricalCrossentropy
from tensorflow.keras.metrics import MeanIoU
from tensorflow.keras.callbacks import ModelCheckpoint
import tensorflow_datasets as tfds
import numpy as np
import cv2

(train_ds, val_ds), info = tfds.load('voc', split=['train','validation'], with_info=True)

num_classes = info.features['labels'].num_classes
input_shape = (224, 224, 3)

def preprocess_dataset(sample):
    #image = sample['image']
    #label = tf.cast(sample['label'],tf.int32)
    image = tf.image.resize(sample['image'], (input_shape[0], input_shape[1]))
    image = tf.cast(image, tf.float32) / 255.0
    label = tf.one_hot(sample['objects']['label'], depth=num_classes)
    return image, label

# Print out the structure of a sample from the dataset
sample = next(iter(train_ds))
print(sample.keys())

train_ds = train_ds.map(preprocess_dataset)
val_ds = val_ds.map(preprocess_dataset)

batch_size = 32
train_ds = train_ds.batch(batch_size)
val_ds = val_ds.batch(batch_size)
test_ds = test_ds.batch(batch_size)

def create_model(input_shape,num_classes):
  base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)
  for layer in base_model.layers:
    layers.trainable=False

  model = models.Sequential([
      base_model,
      layers.Flatten(),
      layers.Dense(1024, activation='relu'),
      layers.Dropout(0.5),
      layers.Dense(num_classes, activation='softmax')
  ])

  return model

model = create_model(input_shape, num_classes)
model.compile(optimizer=Adam(), loss=SparseCategoricalCrossentropy(), metrics=[MeanIoU(num_classes=num_classes)])

checkpoint = ModelCheckpoint("object_detection_model.h5",save_best_only=True)

history = model.fit(train_ds, epochs=10, validation_data=val_ds, callbacks=[checkpoint])

