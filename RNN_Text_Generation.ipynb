{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nEgETy1DKJmH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "(x_train, _), (_, _) = tf.keras.datasets.imdb.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8cKeKkFN_Nf",
        "outputId": "f799d68c-694c-479e-ffa8-3c12337ebbcc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert integer sequences back to text\n",
        "word_index = tf.keras.datasets.imdb.get_word_index()\n",
        "index_word = {idx: word for word, idx in word_index.items()}\n",
        "imdb_reviews = [' '.join([index_word.get(idx - 3, '?') for idx in sequence]) for sequence in x_train]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzUA8xEJN_Q1",
        "outputId": "43229d69-c623-4389-b7a2-8d25452a9128"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1641221/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(imdb_reviews)\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "k42oSivxN_VP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate input-output pairs\n",
        "sequences = tokenizer.texts_to_sequences(imdb_reviews)\n",
        "max_seq_length = max(len(seq) for seq in sequences)\n",
        "sequences = pad_sequences(sequences, maxlen=max_seq_length, padding='pre')\n",
        "X = sequences[:, :-1]\n",
        "y = tf.keras.utils.to_categorical(sequences[:, -1], num_classes=vocab_size)"
      ],
      "metadata": {
        "id": "8-A5teV2N_ad"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "wUWqOOlfN_en"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=256, input_length=max_seq_length-1),\n",
        "    LSTM(units=128),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "vjLRg-88N_iM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "ikz5MY9SN_l-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data generator\n",
        "def data_generator(X, y, batch_size):\n",
        "    while True:\n",
        "        for i in range(0, len(X), batch_size):\n",
        "            X_batch = X[i:i+batch_size]\n",
        "            y_batch = y[i:i+batch_size]\n",
        "            yield X_batch, y_batch"
      ],
      "metadata": {
        "id": "SeuaOicgN_ph"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model using data generator\n",
        "batch_size = 32\n",
        "steps_per_epoch = len(X_train) // batch_size\n",
        "validation_steps = len(X_val) // batch_size\n",
        "\n",
        "train_generator = data_generator(X_train, y_train, batch_size)\n",
        "val_generator = data_generator(X_val, y_val, batch_size)\n",
        "\n",
        "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=10, validation_data=val_generator, validation_steps=validation_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlEbr4kHN_tN",
        "outputId": "2baacfce-feba-4111-f4d5-64965b63b847"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 107s 166ms/step - loss: 8.0466 - val_loss: 7.5854\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 65s 104ms/step - loss: 6.5622 - val_loss: 7.5714\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 65s 105ms/step - loss: 6.0445 - val_loss: 7.6253\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 70s 112ms/step - loss: 5.5111 - val_loss: 7.6557\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 66s 106ms/step - loss: 5.0560 - val_loss: 7.8340\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 66s 106ms/step - loss: 4.6411 - val_loss: 7.8626\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 66s 105ms/step - loss: 4.2622 - val_loss: 7.9732\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 66s 105ms/step - loss: 3.8713 - val_loss: 8.0436\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 67s 107ms/step - loss: 3.4973 - val_loss: 8.0470\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 66s 106ms/step - loss: 3.2143 - val_loss: 8.1985\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d809f878670>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Generate text\n",
        "seed_text = \"The sun\"\n",
        "for _ in range(100):\n",
        "    encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_seq_length-1, truncating='pre')\n",
        "    y_pred_probs = model.predict(encoded)[0]\n",
        "    next_word_index = np.random.choice(len(y_pred_probs), p=y_pred_probs)\n",
        "    next_word = tokenizer.index_word[next_word_index]\n",
        "    seed_text += \" \" + next_word\n",
        "print(seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXzf1PBOOhz7",
        "outputId": "7e592ce7-2fbf-4e79-c01f-f2a97f0d84c9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 472ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "The sun stinks that gem good movie worse junk worse other today cable enjoy it favourite up d warned america audience good airing airing career immediately ii scripts stifler falk net ii ii order films rhonda bother shows note empathy known about people enjoy it pathetic suspense fans feel fights art film together audiences film making it made this film please recommend it off portrayed substance up kiss list please 2005 bad later it else do more beautiful list should better pan justice deliver better swing people go minutes made it so much much see it yet again again once see it\n"
          ]
        }
      ]
    }
  ]
}